# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# see kafka.producer.ProducerConfig for more details

############################# Producer Basics #############################

# list of brokers used for bootstrapping knowledge about the rest of the cluster
# format: host1:port1,host2:port2 ...
metadata.broker.list=mesos3.iit.demokritos.gr:7000

# name of the partitioner class for partitioning events; default partition spreads data randomly
#partitioner.class=

# specifies whether the messages are sent asynchronously (async) or synchronously (sync)
producer.type=sync

# specify the compression codec for all data generated: none , gzip, snappy.
# the old config values work as well: 0, 1, 2 for none, gzip, snappy, respectivally
compression.codec=none

# message encoder
serializer.class=org.speedd.kafka.JsonEventEncoder

# allow topic level compression
#compressed.topics=

############################# Async Producer #############################
# maximum time, in milliseconds, for buffering data on the producer queue 
#queue.buffering.max.ms=

# the maximum size of the blocking queue for buffering on the producer 
#queue.buffering.max.messages=

# Timeout for event enqueue:
# 0: events will be enqueued immediately or dropped if the queue is full
# -ve: enqueue will block indefinitely if the queue is full
# +ve: enqueue will block up to this many milliseconds if the queue is full
#queue.enqueue.timeout.ms=

# the number of messages batched at the producer 
#batch.num.messages=

############################# Consumer Configuration #############################
# Zookeeper connection string
# comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002"
zookeeper.connect=10.0.11.11:2181

# timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=1000000

#consumer group id
#group.id=speedd-consumer-group

#consumer timeout
#consumer.timeout.ms=5000
#Kafka topic to publish to
topic.in.events=speedd-fraud-in-events
topic.out.events=speedd-fraud-out-events
topic.actions=speedd-fraud-actions
topic.actions.confirmed=speedd-fraud-actions-confirmed
topic.admin=speedd-fraud-admin

# Path to Proton's Event Processing Network definition file (JSON)
proton.epnPath=FeedzaiFraudIntegration-perf.json

speedd.inEventScheme=org.speedd.fraud.FraudAggregatedReadingScheme

speedd.cepParallelismHint=16
speedd.inEventReaderParallelismHint=1
speedd.inEventReaderTaskNum=1
speedd.outEventWriterParallelismHint=4
speedd.outEventWriterTaskNum=1
speedd.cepConsumerParallelismHint=1
speedd.cepConsumerTaskNum=1

# Storm topology settings

topology.workers=4
 
speedd.topology.class=org.speedd.fraud.CCFTopology

topology.debug=false

topology.acker.executors=1
#topology.max.task.parallelism=1

topology.max.spout.pending=150
topology.worker.childopts=-Xmx2048m -XX:+UseConcMarkSweepGC -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:NewSize=128m -XX:CMSInitiatingOccupancyFraction=70 -XX:-CMSConcurrentMTEnabled -Djava.net.preferIPv4Stack=true
